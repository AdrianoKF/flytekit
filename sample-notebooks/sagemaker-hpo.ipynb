{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Flyte environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to flyte-staging.lyft.net\n"
     ]
    }
   ],
   "source": [
    "from flytekit.configuration import set_flyte_config_file, platform\n",
    "set_flyte_config_file(\"/Users/changhonghsu/.flyte/notebook-staging.config\")\n",
    "#set_flyte_config_file(\"notebook.config\")\n",
    "\n",
    "print(\"Connected to {}\".format(platform.URL.get()))\n",
    "\n",
    "def print_console_url(exc):\n",
    "    print(\"http://{}/console/projects/{}/domains/{}/executions/{}\".format(platform.URL.get(), exc.id.project, exc.id.domain, exc.id.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker on Flyte -- Launching SageMaker TrainingJob and HPOJob from Flyte (Alpha)\n",
    "\n",
    "To enable seamless and powerful machine learning use cases on Flyte, we are implementing a plugin for Flyte to allow users to leverage some of AWS SageMaker's key functionalities directly from within their Flyte workflows and tasks, so that they can enjoy the excellent data-processing and orchestration capability of Flyte at the same time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Simple Training Job\n",
    "\n",
    "Users can leverage SageMaker's powerful built-in algorithms easily without needing to write any function or logic. They can achieve this by simplying using Flytekit's `SdkSimpleTrainingJobTask` and supplies the settings and the spec of the target algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flytekit.sdk.tasks import inputs\n",
    "from flytekit.sdk.types import Types\n",
    "from flytekit.sdk.workflow import workflow_class, Input, Output\n",
    "from flytekit.common.tasks.sagemaker import training_job_task, hpo_job_task\n",
    "from flytekit.models.sagemaker import training_job as training_job_models, hpo_job as hpo_job_models\n",
    "from flytekit.sdk.sagemaker import types as _sdk_sagemaker_types\n",
    "\n",
    "# Defining the values of some hyperparameters, which will be used by the TrainingJob \n",
    "xgboost_hyperparameters = {\n",
    "    \"num_round\": \"6\",\n",
    "    \"base_score\": \"0.5\",\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"csv_weights\": \"0\",\n",
    "    \"dsplit\": \"row\",\n",
    "    \"grow_policy\": \"depthwise\",\n",
    "    \"lambda_bias\": \"0.0\",\n",
    "    \"max_bin\": \"256\",\n",
    "    \"normalize_type\": \"tree\",\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"one_drop\": \"0\",\n",
    "    \"prob_buffer_row\": \"1.0\",\n",
    "    \"process_type\": \"default\",\n",
    "    \"refresh_leaf\": \"1\",\n",
    "    \"sample_type\": \"uniform\",\n",
    "    \"scale_pos_weight\": \"1.0\",\n",
    "    \"silent\": \"0\",\n",
    "    \"skip_drop\": \"0.0\",\n",
    "    \"tree_method\": \"auto\",\n",
    "    \"tweedie_variance_power\": \"1.5\",\n",
    "    \"updater\": \"grow_colmaker,prune\",\n",
    "}\n",
    "\n",
    "\n",
    "# Users can leverage SageMaker's powerful built-in algorithms easily \n",
    "# without needing to write any function or logic.\n",
    "\n",
    "# When using SageMaker's built-in algorithm mode, users simply \n",
    "# specify the target algorithm, the version of the library (if applicable)\n",
    "# and the target metric they want the training to optimize for\n",
    "\n",
    "alg_spec = training_job_models.AlgorithmSpecification(\n",
    "    input_mode=_sdk_sagemaker_types.InputMode.FILE,\n",
    "    algorithm_name=_sdk_sagemaker_types.AlgorithmName.XGBOOST,\n",
    "    algorithm_version=\"0.72\",\n",
    "    metric_definitions=[\n",
    "        training_job_models.MetricDefinition(name=\"Minimize\", regex=\"validation:error\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# And then they can simply define a training-job task by using SdkSimpleTrainingJobTask \n",
    "# in Flytekit and supplies the settings and the previously defined spec of the built-in \n",
    "# algorithm. Since a SdkSimpleTrainingJobTask inherits from Flytekit's SdkTask, it also\n",
    "# can enjoy the benefit such as caching\n",
    "\n",
    "xgboost_train_task = training_job_task.SdkSimpleTrainingJobTask(\n",
    "    training_job_config=training_job_models.TrainingJobConfig(\n",
    "        instance_type=\"ml.m4.xlarge\",\n",
    "        instance_count=1,\n",
    "        volume_size_in_gb=25,\n",
    "    ),\n",
    "    algorithm_specification=alg_spec,\n",
    "    cache_version='2',\n",
    "    cacheable=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing faster iterations with single task execution -- running the TrainingJob Task standalone\n",
    "\n",
    "The single-task execution capability in Flyte allows users to run their tasks without a workflow. This allow users to do faster iterations purely from inside their notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flytekit.models.sagemaker.training_job import StoppingCondition\n",
    "\n",
    "training_inputs={\n",
    "    \"train\": \"s3://lyft-modelbuilder/test-datasets/pima-indians/train\",\n",
    "    \"validation\": \"s3://lyft-modelbuilder/test-datasets/pima-indians/validation\",\n",
    "    \"static_hyperparameters\": xgboost_hyperparameters,\n",
    "    \"stopping_condition\": StoppingCondition(\n",
    "        max_runtime_in_seconds=43200,\n",
    "    ).to_flyte_idl(),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://flyte-staging.lyft.net/console/projects/flyteexamples/domains/development/executions/peetm5bfmf\n"
     ]
    }
   ],
   "source": [
    "# Invoking the SdkSimpleTrainingJobTask\n",
    "training_exc = xgboost_train_task.register_and_launch(\"flyteexamples\", \"development\", inputs=training_inputs)\n",
    "print_console_url(training_exc)\n",
    "\n",
    "\n",
    "# [A working example]\n",
    "# https://flyte-staging.lyft.net/console/projects/flyteexamples/domains/development/executions/soxtmrw4am\n",
    "\n",
    "# [A failed example]\n",
    "# http://flyte-staging.lyft.net/console/projects/flyteexamples/domains/development/executions/w11i8a1njq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_exc.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping a Training Job inside a Hyperparameter Optimization Job\n",
    "\n",
    "Sometimes, training with a static set of hyperparameters might not yield the desired results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithmSpecification': {'algorithmName': 'XGBOOST', 'algorithmVersion': '0.72', 'metricDefinitions': [{'name': 'Minimize', 'regex': 'validation:error'}]}, 'trainingJobConfig': {'instanceCount': '1', 'instanceType': 'ml.m4.xlarge', 'volumeSizeInGb': '25'}}\n",
      "{'hpo_job_config': type {\n",
      "  simple: BINARY\n",
      "  metadata {\n",
      "    fields {\n",
      "      key: \"pb_type\"\n",
      "      value {\n",
      "        string_value: \"flyteidl.plugins.sagemaker.hpo_job_pb2.HPOJobConfig\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", 'static_hyperparameters': type {\n",
      "  simple: STRUCT\n",
      "}\n",
      ", 'train': type {\n",
      "  blob {\n",
      "    format: \"csv\"\n",
      "    dimensionality: MULTIPART\n",
      "  }\n",
      "}\n",
      ", 'validation': type {\n",
      "  blob {\n",
      "    format: \"csv\"\n",
      "    dimensionality: MULTIPART\n",
      "  }\n",
      "}\n",
      ", 'stopping_condition': type {\n",
      "  simple: BINARY\n",
      "  metadata {\n",
      "    fields {\n",
      "      key: \"pb_type\"\n",
      "      value {\n",
      "        string_value: \"flyteidl.plugins.sagemaker.training_job_pb2.StoppingCondition\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Let's wrap the previously defined SdkSimpleTrainingJobTask\n",
    "# inside a SdkSimpleHPOJobTask and config the HPOJob task a little bit\n",
    "\n",
    "xgboost_hpo_task = hpo_job_task.SdkSimpleHPOJobTask(\n",
    "    training_job=xgboost_train_task,\n",
    "    max_number_of_training_jobs=10,\n",
    "    max_parallel_training_jobs=5,\n",
    "    cache_version='2',\n",
    "    retries=2,\n",
    "    cacheable=True,\n",
    ")\n",
    "\n",
    "# We can print out the SdkSimpleHPOJobTask's trainingJob field to \n",
    "# verify if the definition is wrapped correctly\n",
    "print(xgboost_hpo_task.custom['trainingJob'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Let's run the Hyperparameter Optimization Job standalone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://flyte-staging.lyft.net/console/projects/flyteexamples/domains/development/executions/zxr1n4911g\n"
     ]
    }
   ],
   "source": [
    "from flytekit.models.sagemaker.training_job import StoppingCondition\n",
    "from flytekit.models.sagemaker.hpo_job import HPOJobConfig, HyperparameterTuningObjective\n",
    "from flytekit.models.sagemaker.parameter_ranges import ParameterRanges, CategoricalParameterRange, ContinuousParameterRange, IntegerParameterRange\n",
    "\n",
    "# When launching the TrainingJob and HPOJob, we need to define the inputs.\n",
    "# Inputs are those directly related to algorithm outputs. We use the inputs\n",
    "# and the version information to decide cache hit/miss\n",
    "\n",
    "hpo_inputs={\n",
    "    \"train\": \"s3://lyft-modelbuilder/test-datasets/pima-indians/train\",\n",
    "    \"validation\": \"s3://lyft-modelbuilder/test-datasets/pima-indians/validation\",\n",
    "    \"static_hyperparameters\": xgboost_hyperparameters,\n",
    "    \"stopping_condition\": StoppingCondition(\n",
    "        max_runtime_in_seconds=43200,\n",
    "    ).to_flyte_idl(),\n",
    "    \"hpo_job_config\": HPOJobConfig(\n",
    "        \n",
    "        #############################################\n",
    "        # Define the tunable hyperparameters and the \n",
    "        # range/set of possible values of each hp\n",
    "        #############################################\n",
    "        hyperparameter_ranges=ParameterRanges(\n",
    "            parameter_range_map={\n",
    "                \"max_depth\": IntegerParameterRange(min_value=5, max_value=7, \n",
    "                                                   scaling_type=_sdk_sagemaker_types.HyperparameterScalingType.LINEAR),\n",
    "                # Untunable hyperparameter in XGBoost 0.72\n",
    "                \"rate_drop\": ContinuousParameterRange(min_value=0.0, max_value=0.1,\n",
    "                                                      scaling_type=_sdk_sagemaker_types.HyperparameterScalingType.LINEAR),\n",
    "#                 \"gamma\": ContinuousParameterRange(min_value=0.0, max_value=0.3,\n",
    "#                                                   scaling_type=_sdk_sagemaker_types.HyperparameterScalingType.LINEAR),\n",
    "            }\n",
    "        ),\n",
    "        tuning_strategy=_sdk_sagemaker_types.HyperparameterTuningStrategy.BAYESIAN,\n",
    "        tuning_objective=HyperparameterTuningObjective(\n",
    "            objective_type=_sdk_sagemaker_types.HyperparameterTuningObjectiveType.MINIMIZE,\n",
    "            metric_name=\"validation:error\",\n",
    "        ),\n",
    "        training_job_early_stopping_type=_sdk_sagemaker_types.TrainingJobEarlyStoppingType.AUTO\n",
    "    ).to_flyte_idl(),\n",
    "}\n",
    "\n",
    "## Register and launch the task standalone!\n",
    "hpo_exc = xgboost_hpo_task.register_and_launch(\"flyteexamples\", \"development\", inputs=hpo_inputs)\n",
    "print_console_url(hpo_exc)\n",
    "\n",
    "# [A working example]\n",
    "# https://flyte-staging.lyft.net/console/projects/flyteexamples/domains/development/executions/zw6oqashn6\n",
    "# https://flyte-staging.lyft.net/console/projects/flyteexamples/domains/development/executions/zxr1n4911g\n",
    "\n",
    "# [A failed example]\n",
    "# https://flyte-staging.lyft.net/console/projects/flyteexamples/domains/development/executions/pr8nzuxl7o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_exc.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Can I launch my SageMaker tasks in a Workflow too?\n",
    "Of course! After the users are satisfied with the TrainingJob task and HPOJob task definitions and want to see how it plays with the other components in their pipelines, they can just directly invoke the same tasks they've been iterating on inside their workflows.\n",
    "\n",
    "In this next cell, let's define and register some `SdkPrestoTask`'s to fetch the data from Presto instead of relying on an external CSV file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from flytekit.common.tasks.task import SdkTask\n",
    "from flytekit.sdk.workflow import workflow_class, Input, Output\n",
    "from flytekit.models.sagemaker.training_job import StoppingCondition\n",
    "from flytekit.models.sagemaker.hpo_job import HPOJobConfig, HyperparameterTuningObjective\n",
    "from flytekit.models.sagemaker.parameter_ranges import ParameterRanges, CategoricalParameterRange, ContinuousParameterRange, IntegerParameterRange\n",
    "from flytekit.common.tasks.presto_task import SdkPrestoTask\n",
    "from flytekit.sdk.tasks import inputs\n",
    "\n",
    "from os import environ\n",
    "environ[\"version\"] = \"29\"\n",
    "environ[\"spec_version\"] = \"29-1\"\n",
    "\n",
    "get_train_data2 = SdkPrestoTask(\n",
    "    task_inputs=inputs(),\n",
    "    statement=\"\"\"\n",
    "    SELECT * \n",
    "    FROM hive.flyte.datacouncildemo_train\n",
    "    \"\"\",\n",
    "    output_schema=Types.Schema(),\n",
    "    discoverable=True,\n",
    "    discovery_version=\"3\",\n",
    ")\n",
    "get_train_data2.register(project=\"flytesnacks\", domain=\"development\", name=\"get_train_data\", version=environ[\"version\"])\n",
    "\n",
    "get_validation_data = SdkPrestoTask(\n",
    "    task_inputs=inputs(),\n",
    "    statement=\"\"\"\n",
    "    SELECT * \n",
    "    FROM hive.flyte.datacouncildemo_validation\n",
    "    \"\"\",\n",
    "    output_schema=Types.Schema(),\n",
    "    discoverable=True,\n",
    "    discovery_version=\"2\",\n",
    ")\n",
    "get_validation_data.register(project=\"flytesnacks\", domain=\"development\", name=\"get_validation_data\", version=environ[\"version\"])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Don't re-invent the wheels\n",
    "Note that, the `SdkPrestoTask`'s will generate parquet files, but the `TrainingJob` and `HPOJob` we defined earlier requires inputs to be in CSV format. Fortunately, somebody has already writen a common python task that transforms parquet to CSV. **Let's just import that task and use it.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data transformation task\n",
    "transform_parquet_to_csv = SdkTask.fetch(project=\"flytesnacks\", domain=\"development\", name=\"transform_parquet_to_csv\", version=\"24\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's create a workflow wrapping the  `SdkSimpleHPOJobTask` we defined earlier\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "@workflow_class()\n",
    "class TrainingWorkflow(object):    \n",
    "    \n",
    "    # Retrieve data\n",
    "    train_data = get_train_data2()\n",
    "    validation_data = get_validation_data()\n",
    "    \n",
    "    # Transform data\n",
    "    train_csv = transform_parquet_to_csv(input_parquet=train_data.outputs.results)\n",
    "    validation_csv = transform_parquet_to_csv(input_parquet=validation_data.outputs.results)\n",
    "    \n",
    "    # Invoking the same HPO task we defined earlier\n",
    "    train = xgboost_hpo_task(\n",
    "        # Using the input we got from the Presto tasks\n",
    "        train=train_csv.outputs.output_csv,\n",
    "        validation=validation_csv.outputs.output_csv,\n",
    "        \n",
    "        static_hyperparameters=xgboost_hyperparameters,\n",
    "        stopping_condition=StoppingCondition(max_runtime_in_seconds=43200).to_flyte_idl(),\n",
    "        hpo_job_config=HPOJobConfig(    \n",
    "            hyperparameter_ranges=ParameterRanges(\n",
    "                parameter_range_map={\n",
    "                \"max_depth\": IntegerParameterRange(min_value=5, max_value=7, \n",
    "                                                   scaling_type=_sdk_sagemaker_types.HyperparameterScalingType.LINEAR),\n",
    "                }\n",
    "            ),\n",
    "            tuning_strategy=_sdk_sagemaker_types.HyperparameterTuningStrategy.BAYESIAN,\n",
    "            tuning_objective=HyperparameterTuningObjective(\n",
    "                objective_type=_sdk_sagemaker_types.HyperparameterTuningObjectiveType.MINIMIZE,\n",
    "                metric_name=\"validation:error\",\n",
    "            ),\n",
    "            training_job_early_stopping_type=_sdk_sagemaker_types.TrainingJobEarlyStoppingType.AUTO\n",
    "        ).to_flyte_idl(),\n",
    "    )\n",
    "    \n",
    "    model = Output(train.outputs.model, sdk_type=Types.Blob)\n",
    "    \n",
    "TrainingWorkflow.register(project=\"flyteexamples\", domain=\"development\", name=\"TrainingWorkflow\", version=environ[\"spec_version\"])\n",
    "TrainingWorkflow_lp = TrainingWorkflow.create_launch_plan()\n",
    "TrainingWorkflow_lp.register(project=\"flyteexamples\", domain=\"development\", name=\"TrainingWorkflow\", version=environ[\"spec_version\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exec = TrainingWorkflow_lp.launch(project=\"flyteexamples\", domain=\"development\", inputs={})\n",
    "print_console_url(exec)\n",
    "\n",
    "# [A working example]\n",
    "# https://flyte-staging.lyft.net/console/projects/flytesnacks/domains/development/executions/f9e645a85e0164b0a9b3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tsk:flytesnacks:development:get_validation_data:29'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't re-invent the wheels\n",
    "Note that, the `SdkPrestoTask`'s will generate parquet files, but the `TrainingJob` and `HPOJob` we defined earlier requires inputs to be in CSV format. Fortunately, somebody has already writen a common python task that transforms parquet to CSV. **Let's just import that task and use it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformation task\n",
    "transform_parquet_to_csv = SdkTask.fetch(project=\"flytesnacks\", domain=\"development\", name=\"transform_parquet_to_csv\", version=\"24\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create a workflow wrapping the  `SdkSimpleHPOJobTask` we defined earlier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lp:flyteexamples:development:TrainingWorkflow:29-1'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "@workflow_class()\n",
    "class TrainingWorkflow(object):    \n",
    "    \n",
    "    # Retrieve data\n",
    "    train_data = get_train_data2()\n",
    "    validation_data = get_validation_data()\n",
    "    \n",
    "    # Transform data\n",
    "    train_csv = transform_parquet_to_csv(input_parquet=train_data.outputs.results)\n",
    "    validation_csv = transform_parquet_to_csv(input_parquet=validation_data.outputs.results)\n",
    "    \n",
    "    # Invoking the same HPO task we defined earlier\n",
    "    train = xgboost_hpo_task(\n",
    "        # Using the input we got from the Presto tasks\n",
    "        train=train_csv.outputs.output_csv,\n",
    "        validation=validation_csv.outputs.output_csv,\n",
    "        \n",
    "        static_hyperparameters=xgboost_hyperparameters,\n",
    "        stopping_condition=StoppingCondition(max_runtime_in_seconds=43200).to_flyte_idl(),\n",
    "        hpo_job_config=HPOJobConfig(    \n",
    "            hyperparameter_ranges=ParameterRanges(\n",
    "                parameter_range_map={\n",
    "                \"max_depth\": IntegerParameterRange(min_value=5, max_value=7, \n",
    "                                                   scaling_type=_sdk_sagemaker_types.HyperparameterScalingType.LINEAR),\n",
    "                }\n",
    "            ),\n",
    "            tuning_strategy=_sdk_sagemaker_types.HyperparameterTuningStrategy.BAYESIAN,\n",
    "            tuning_objective=HyperparameterTuningObjective(\n",
    "                objective_type=_sdk_sagemaker_types.HyperparameterTuningObjectiveType.MINIMIZE,\n",
    "                metric_name=\"validation:error\",\n",
    "            ),\n",
    "            training_job_early_stopping_type=_sdk_sagemaker_types.TrainingJobEarlyStoppingType.AUTO\n",
    "        ).to_flyte_idl(),\n",
    "    )\n",
    "    \n",
    "    model = Output(train.outputs.model, sdk_type=Types.Blob)\n",
    "    \n",
    "TrainingWorkflow.register(project=\"flyteexamples\", domain=\"development\", name=\"TrainingWorkflow\", version=environ[\"spec_version\"])\n",
    "TrainingWorkflow_lp = TrainingWorkflow.create_launch_plan()\n",
    "TrainingWorkflow_lp.register(project=\"flyteexamples\", domain=\"development\", name=\"TrainingWorkflow\", version=environ[\"spec_version\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://flyte-staging.lyft.net/console/projects/flyteexamples/domains/development/executions/f5fe2f8f8dd104b3291f\n"
     ]
    }
   ],
   "source": [
    "exec = TrainingWorkflow_lp.launch(project=\"flyteexamples\", domain=\"development\", inputs={})\n",
    "print_console_url(exec)\n",
    "\n",
    "# [A working example]\n",
    "# https://flyte-staging.lyft.net/console/projects/flytesnacks/domains/development/executions/f9e645a85e0164b0a9b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}